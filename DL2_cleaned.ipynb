{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "collapsed": true,
    "id": "YIuApjgk2MMV",
    "outputId": "6d6407bd-4181-48cd-c0bf-92fad22298a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2541
    },
    "id": "l4ceeHmh5WI0",
    "outputId": "b84b5412-eade-423f-da06-7b79466676af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sample:\n",
      "   devanagari     latin\n",
      "0         à¤…à¤‚        an\n",
      "1    à¤…à¤‚à¤•à¤—à¤£à¤¿à¤¤  ankganit\n",
      "2       à¤…à¤‚à¤•à¤²     uncle\n",
      "3      à¤…à¤‚à¤•à¥à¤°     ankur\n",
      "4     à¤…à¤‚à¤•à¥à¤°à¤£   ankuran\n",
      "Latin vocab size: 27\n",
      "Devanagari vocab size: 64\n",
      "Train Input Shape: (44202, 20)\n",
      "Train Output Shape (one-hot): (44202, 19, 64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ input_layer_1       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,350</span> â”‚ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_1         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,200</span> â”‚ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">314,368</span> â”‚ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      â”‚            â”‚                   â”‚\n",
       "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">314,368</span> â”‚ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
       "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      â”‚            â”‚ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     â”‚\n",
       "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      â”‚            â”‚ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> â”‚ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ input_layer_1       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m50\u001b[0m)    â”‚      \u001b[38;5;34m1,350\u001b[0m â”‚ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_1         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m50\u001b[0m)    â”‚      \u001b[38;5;34m3,200\u001b[0m â”‚ input_layer_1[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     â”‚    \u001b[38;5;34m314,368\u001b[0m â”‚ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      â”‚            â”‚                   â”‚\n",
       "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m), â”‚    \u001b[38;5;34m314,368\u001b[0m â”‚ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
       "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      â”‚            â”‚ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     â”‚\n",
       "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      â”‚            â”‚ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚     \u001b[38;5;34m16,448\u001b[0m â”‚ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">649,734</span> (2.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m649,734\u001b[0m (2.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">649,734</span> (2.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m649,734\u001b[0m (2.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.6909 - loss: 1.3509 - val_accuracy: 0.7070 - val_loss: 1.2421\n",
      "Epoch 2/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.7429 - loss: 0.9304 - val_accuracy: 0.7236 - val_loss: 1.2489\n",
      "Epoch 3/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7773 - loss: 0.7808 - val_accuracy: 0.7374 - val_loss: 1.2211\n",
      "Epoch 4/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.8157 - loss: 0.6324 - val_accuracy: 0.7526 - val_loss: 1.1188\n",
      "Epoch 5/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8526 - loss: 0.4931 - val_accuracy: 0.7785 - val_loss: 0.9815\n",
      "Epoch 6/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8894 - loss: 0.3625 - val_accuracy: 0.8003 - val_loss: 0.8598\n",
      "Epoch 7/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9141 - loss: 0.2799 - val_accuracy: 0.8097 - val_loss: 0.8153\n",
      "Epoch 8/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9291 - loss: 0.2290 - val_accuracy: 0.8145 - val_loss: 0.8013\n",
      "Epoch 9/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9401 - loss: 0.1942 - val_accuracy: 0.8173 - val_loss: 0.7955\n",
      "Epoch 10/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9479 - loss: 0.1685 - val_accuracy: 0.8217 - val_loss: 0.8008\n",
      "Epoch 11/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9548 - loss: 0.1478 - val_accuracy: 0.8217 - val_loss: 0.8126\n",
      "Epoch 12/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9600 - loss: 0.1308 - val_accuracy: 0.8211 - val_loss: 0.8446\n",
      "Epoch 13/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9645 - loss: 0.1160 - val_accuracy: 0.8207 - val_loss: 0.8553\n",
      "Epoch 14/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9688 - loss: 0.1032 - val_accuracy: 0.8210 - val_loss: 0.8803\n",
      "Epoch 15/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9724 - loss: 0.0918 - val_accuracy: 0.8210 - val_loss: 0.9046\n",
      "Epoch 16/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9752 - loss: 0.0826 - val_accuracy: 0.8220 - val_loss: 0.9284\n",
      "Epoch 17/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9775 - loss: 0.0752 - val_accuracy: 0.8148 - val_loss: 1.0018\n",
      "Epoch 18/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9796 - loss: 0.0683 - val_accuracy: 0.8200 - val_loss: 1.0305\n",
      "Epoch 19/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9813 - loss: 0.0620 - val_accuracy: 0.8190 - val_loss: 1.0560\n",
      "Epoch 20/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9830 - loss: 0.0565 - val_accuracy: 0.8206 - val_loss: 1.0546\n",
      "Epoch 21/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9847 - loss: 0.0517 - val_accuracy: 0.8183 - val_loss: 1.0713\n",
      "Epoch 22/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9863 - loss: 0.0463 - val_accuracy: 0.8175 - val_loss: 1.1193\n",
      "Epoch 23/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9876 - loss: 0.0423 - val_accuracy: 0.8141 - val_loss: 1.1543\n",
      "Epoch 24/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9886 - loss: 0.0390 - val_accuracy: 0.8105 - val_loss: 1.2043\n",
      "Epoch 25/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9885 - loss: 0.0381 - val_accuracy: 0.8138 - val_loss: 1.2304\n",
      "Epoch 26/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9895 - loss: 0.0355 - val_accuracy: 0.8169 - val_loss: 1.2345\n",
      "Epoch 27/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9902 - loss: 0.0329 - val_accuracy: 0.8154 - val_loss: 1.2443\n",
      "Epoch 28/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9906 - loss: 0.0312 - val_accuracy: 0.8124 - val_loss: 1.2904\n",
      "Epoch 29/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9912 - loss: 0.0293 - val_accuracy: 0.8154 - val_loss: 1.3081\n",
      "Epoch 30/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9919 - loss: 0.0272 - val_accuracy: 0.8165 - val_loss: 1.3156\n",
      "Epoch 31/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9921 - loss: 0.0268 - val_accuracy: 0.8151 - val_loss: 1.3389\n",
      "Epoch 32/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9925 - loss: 0.0251 - val_accuracy: 0.8166 - val_loss: 1.3295\n",
      "Epoch 33/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9929 - loss: 0.0240 - val_accuracy: 0.8154 - val_loss: 1.3646\n",
      "Epoch 34/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9935 - loss: 0.0219 - val_accuracy: 0.8115 - val_loss: 1.3860\n",
      "Epoch 35/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9932 - loss: 0.0224 - val_accuracy: 0.8127 - val_loss: 1.3728\n",
      "Epoch 36/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9931 - loss: 0.0225 - val_accuracy: 0.8099 - val_loss: 1.4473\n",
      "Epoch 37/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9935 - loss: 0.0213 - val_accuracy: 0.8078 - val_loss: 1.4717\n",
      "Epoch 38/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9938 - loss: 0.0205 - val_accuracy: 0.8118 - val_loss: 1.4797\n",
      "Epoch 39/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9937 - loss: 0.0206 - val_accuracy: 0.8167 - val_loss: 1.4511\n",
      "Epoch 40/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9939 - loss: 0.0199 - val_accuracy: 0.8176 - val_loss: 1.4154\n",
      "Epoch 41/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9940 - loss: 0.0199 - val_accuracy: 0.8140 - val_loss: 1.4551\n",
      "Epoch 42/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9940 - loss: 0.0193 - val_accuracy: 0.8112 - val_loss: 1.5343\n",
      "Epoch 43/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9943 - loss: 0.0186 - val_accuracy: 0.8120 - val_loss: 1.5167\n",
      "Epoch 44/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0183 - val_accuracy: 0.8096 - val_loss: 1.5912\n",
      "Epoch 45/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9948 - loss: 0.0175 - val_accuracy: 0.8123 - val_loss: 1.6149\n",
      "Epoch 46/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9944 - loss: 0.0178 - val_accuracy: 0.8052 - val_loss: 1.6185\n",
      "Epoch 47/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9945 - loss: 0.0179 - val_accuracy: 0.8076 - val_loss: 1.5939\n",
      "Epoch 48/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9946 - loss: 0.0173 - val_accuracy: 0.8067 - val_loss: 1.6354\n",
      "Epoch 49/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9948 - loss: 0.0169 - val_accuracy: 0.8097 - val_loss: 1.6146\n",
      "Epoch 50/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9945 - loss: 0.0177 - val_accuracy: 0.8074 - val_loss: 1.6533\n",
      "\u001b[1m141/141\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9238 - loss: 0.4120\n",
      "Test Accuracy: 90.80%\n",
      "\n",
      "Latin Input       : ank\n",
      "Actual Devanagari : à¤…à¤‚à¤•\n",
      "Predicted Output  : à¤à¤‚à¤•\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 2. Load and Clean the Dataset\n",
    "train_df = pd.read_csv('/content/hi.translit.sampled.train.tsv', sep='\\t', header=None, encoding='utf-8')\n",
    "test_df = pd.read_csv('/content/hi.translit.sampled.test.tsv', sep='\\t', header=None, encoding='utf-8')\n",
    "dev_df = pd.read_csv('/content/hi.translit.sampled.dev.tsv', sep='\\t', header=None, encoding='utf-8')\n",
    "\n",
    "# Drop unwanted third column and rename\n",
    "train_df = train_df.drop(columns=[2])\n",
    "test_df = test_df.drop(columns=[2])\n",
    "dev_df = dev_df.drop(columns=[2])\n",
    "\n",
    "train_df.columns = ['devanagari', 'latin']\n",
    "test_df.columns = ['devanagari', 'latin']\n",
    "dev_df.columns = ['devanagari', 'latin']\n",
    "\n",
    "# Drop NaNs and convert to strings\n",
    "for df in [train_df, test_df, dev_df]:\n",
    "    df.dropna(inplace=True)\n",
    "    df['latin'] = df['latin'].astype(str)\n",
    "    df['devanagari'] = df['devanagari'].astype(str)\n",
    "\n",
    "print(\"Train Sample:\\n\", train_df.head())\n",
    "\n",
    "# 3. Tokenize the Texts\n",
    "latin_tokenizer = Tokenizer(char_level=True)\n",
    "latin_tokenizer.fit_on_texts(train_df['latin'])\n",
    "\n",
    "devanagari_tokenizer = Tokenizer(char_level=True)\n",
    "devanagari_tokenizer.fit_on_texts(train_df['devanagari'])\n",
    "\n",
    "input_vocab_size = len(latin_tokenizer.word_index) + 1\n",
    "output_vocab_size = len(devanagari_tokenizer.word_index) + 1\n",
    "\n",
    "print(f\"Latin vocab size: {input_vocab_size}\")\n",
    "print(f\"Devanagari vocab size: {output_vocab_size}\")\n",
    "\n",
    "# 4. Prepare the Data for Training\n",
    "train_input_seq = latin_tokenizer.texts_to_sequences(train_df['latin'])\n",
    "train_output_seq = devanagari_tokenizer.texts_to_sequences(train_df['devanagari'])\n",
    "\n",
    "max_input_length = max(len(seq) for seq in train_input_seq)\n",
    "max_output_length = max(len(seq) for seq in train_output_seq)\n",
    "\n",
    "train_input_seq = pad_sequences(train_input_seq, maxlen=max_input_length, padding='post')\n",
    "train_output_seq = pad_sequences(train_output_seq, maxlen=max_output_length, padding='post')\n",
    "\n",
    "train_output_seq_one_hot = np.array([\n",
    "    to_categorical(seq, num_classes=output_vocab_size)\n",
    "    for seq in train_output_seq\n",
    "])\n",
    "\n",
    "print(f\"Train Input Shape: {train_input_seq.shape}\")\n",
    "print(f\"Train Output Shape (one-hot): {train_output_seq_one_hot.shape}\")\n",
    "\n",
    "# 5. Define the Seq2Seq Model\n",
    "def define_model(input_vocab_size, output_vocab_size, input_timesteps, output_timesteps, embedding_dim, hidden_units):\n",
    "    encoder_inputs = Input(shape=(input_timesteps,))\n",
    "    encoder_embedding = Embedding(input_vocab_size, embedding_dim)(encoder_inputs)\n",
    "    encoder_outputs, state_h, state_c = LSTM(hidden_units, return_state=True)(encoder_embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    decoder_inputs = Input(shape=(output_timesteps,))\n",
    "    decoder_embedding = Embedding(output_vocab_size, embedding_dim)(decoder_inputs)\n",
    "    decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "embedding_dim = 50\n",
    "hidden_units = 256\n",
    "model = define_model(input_vocab_size, output_vocab_size, max_input_length, max_output_length, embedding_dim, hidden_units)\n",
    "model.summary()\n",
    "\n",
    "# 6. Train the Model\n",
    "decoder_input_train = np.zeros_like(train_output_seq)\n",
    "decoder_input_train[:, 1:] = train_output_seq[:, :-1]\n",
    "\n",
    "model.fit(\n",
    "    [train_input_seq, decoder_input_train],\n",
    "    train_output_seq_one_hot,\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# 7. Evaluate the Model\n",
    "test_input_seq = latin_tokenizer.texts_to_sequences(test_df['latin'])\n",
    "test_output_seq = devanagari_tokenizer.texts_to_sequences(test_df['devanagari'])\n",
    "\n",
    "test_input_seq = pad_sequences(test_input_seq, maxlen=max_input_length, padding='post')\n",
    "test_output_seq = pad_sequences(test_output_seq, maxlen=max_output_length, padding='post')\n",
    "\n",
    "decoder_input_test = np.zeros_like(test_output_seq)\n",
    "decoder_input_test[:, 1:] = test_output_seq[:, :-1]\n",
    "\n",
    "test_output_seq_one_hot = np.array([\n",
    "    to_categorical(seq, num_classes=output_vocab_size)\n",
    "    for seq in test_output_seq\n",
    "])\n",
    "\n",
    "test_loss, test_acc = model.evaluate([test_input_seq, decoder_input_test], test_output_seq_one_hot)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "\n",
    "# 8. Make Predictions\n",
    "def decode_sequence(input_seq):\n",
    "    decoder_input = np.zeros((1, max_output_length))\n",
    "    for i in range(max_output_length):\n",
    "        output_tokens = model.predict([input_seq, decoder_input], verbose=0)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, i, :])\n",
    "        decoder_input[0, i] = sampled_token_index\n",
    "    predicted_seq = decoder_input[0]\n",
    "    predicted_text = ''.join([devanagari_tokenizer.index_word.get(int(i), '') for i in predicted_seq if i != 0])\n",
    "    return predicted_text\n",
    "\n",
    "# Predict on one test sample\n",
    "sample_input = test_input_seq[0:1]\n",
    "predicted_output = decode_sequence(sample_input)\n",
    "print(f\"\\nLatin Input       : {test_df.iloc[0]['latin']}\")\n",
    "print(f\"Actual Devanagari : {test_df.iloc[0]['devanagari']}\")\n",
    "print(f\"Predicted Output  : {predicted_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712,
     "referenced_widgets": [
      "01e7aac657f64f78a6ba5097a294082e",
      "e1ded37cd749422daf84ea6341ef1489",
      "89d9b0f82a81471ba5d3bfe34ee2e21e",
      "b2900025e0bd410b95843c57338f7232",
      "57665c03d09c4fc6b3bd5b8d159c6318",
      "3941851ed0544415956bbe61e11abeee",
      "82acedd8b2ec48fcbff3ed1d43da7eca",
      "674805b3637b4063a08314b5585a96cf",
      "e63444ebe48147778c9fc23544610234",
      "95e2471ae17a4dc0817d8b5169b7e73f",
      "7b28477a43cd47bfbb9e1d3ce7582039",
      "9898745b12f0495bbc5a39f311fcadd9",
      "03d5049a139a4aab8103c7f80a5e249a",
      "cfe8172268c94a9c92e4725f71411db6",
      "263d89ec985f413d92dae13e8df92641",
      "b492a9ae00914a91a2c37a8eb8693662",
      "a45fef142e37463bb74efac36433dae4",
      "fadfdfdc781943d797a5d3d90e9d793a",
      "d910af93407b4c119a844a2eb8194e03",
      "a8d3220e7a1c4f3f842690b02547cfa4",
      "1cd76b7efaf2453fb96dde063cea6131",
      "58b065b341514a5e8150fdbe47bd796a"
     ]
    },
    "id": "aTTdRJGObEs-",
    "outputId": "703ea8c6-2465-4fd2-8e2a-d374599c11f5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e7aac657f64f78a6ba5097a294082e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9898745b12f0495bbc5a39f311fcadd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-a3eb8d2522ed>:67: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='681' max='681' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [681/681 02:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.935600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.784300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.687600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.645800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.573400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.506000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.298000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.253000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.349300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.166600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.214700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.455800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¶ Lyrics\n",
      "\n",
      "Under the neon lights, we danced for the rest of the night, and they had the good fortune to see it fall on them instead of the rest of the crowd. After dancing for one minute, each time everyone seemed to be doing a different thing from him. Finally, a guy on stage started talking about his friend's parents â€” maybe something along the lines of: \"We lost the boy at the hands of our dad in his thuggish way. I was right â€” I was right. He\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    GPT2Tokenizer, GPT2LMHeadModel,\n",
    "    Trainer, TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    pipeline, set_seed\n",
    ")\n",
    "\n",
    "# ---------- Step 1: Load and Clean Lyrics ----------\n",
    "def clean_lyrics(lyric):\n",
    "    if pd.isna(lyric):\n",
    "        return \"\"\n",
    "    lyric = re.sub(r'^#+', '', str(lyric))\n",
    "    lyric = lyric.encode('utf-8').decode('utf-8', 'ignore')\n",
    "    lyric = re.sub(r'[\\u2018\\u2019\\u201c\\u201d]+', \"'\", lyric)\n",
    "    lyric = re.sub(r'[^\\x00-\\x7F]+', '', lyric)\n",
    "    return lyric.strip()\n",
    "\n",
    "def load_and_clean_lyrics(file_paths):\n",
    "    df = pd.concat([pd.read_csv(path) for path in file_paths], ignore_index=True)\n",
    "    if 'Lyric' not in df.columns:\n",
    "        raise ValueError(\"Missing 'Lyric' column.\")\n",
    "    df['Lyric'] = df['Lyric'].astype(str).apply(clean_lyrics)\n",
    "    return df['Lyric'].dropna().tolist()\n",
    "\n",
    "# ---------- Step 2: Tokenizer and Dataset ----------\n",
    "def get_tokenizer_and_model(model_name=\"gpt2\"):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    return tokenizer, model\n",
    "\n",
    "def prepare_dataset(lyrics, tokenizer, max_length=512):\n",
    "    dataset = Dataset.from_dict({\"text\": lyrics})\n",
    "\n",
    "    def tokenize(example):\n",
    "        return tokenizer(\n",
    "            example[\"text\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_length\n",
    "        )\n",
    "\n",
    "    dataset = dataset.map(tokenize, batched=True)\n",
    "    dataset = dataset.map(lambda x: {\"labels\": x[\"input_ids\"]}, batched=True)\n",
    "    return dataset\n",
    "\n",
    "# ---------- Step 3: Train ----------\n",
    "def train_model(dataset, model, tokenizer):\n",
    "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./gpt2-lyrics-output\",\n",
    "        per_device_train_batch_size=2,\n",
    "        num_train_epochs=3,\n",
    "        logging_steps=50,\n",
    "        save_steps=500,\n",
    "        save_total_limit=1,\n",
    "        report_to=\"none\",\n",
    "        prediction_loss_only=True,\n",
    "        fp16=False  # Set True if using GPU w/ float16 support\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "# ---------- Step 4: Generate ----------\n",
    "def generate_lyrics(prompt=\"Under the neon lights, we danced\"):\n",
    "    tokenizer, model = get_tokenizer_and_model()\n",
    "    generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "    set_seed(42)\n",
    "    output = generator(prompt, max_length=100, num_return_sequences=1)\n",
    "    print(\"\\nğŸ¶ Lyrics\\n\")\n",
    "    print(output[0][\"generated_text\"])\n",
    "\n",
    "# ---------- Main ----------\n",
    "if __name__ == \"__main__\":\n",
    "    file_paths = [\"/content/ArianaGrande.csv\", \"/content/BillieEilish.csv\"]\n",
    "    lyrics = load_and_clean_lyrics(file_paths)\n",
    "    tokenizer, model = get_tokenizer_and_model()\n",
    "    dataset = prepare_dataset(lyrics, tokenizer)\n",
    "    train_model(dataset, model, tokenizer)\n",
    "    generate_lyrics(prompt=\"Under the neon lights, we danced\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
